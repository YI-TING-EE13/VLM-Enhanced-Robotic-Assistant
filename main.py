# main.py
"""
Main entry point for the VLM-Enhanced Robot Assistant application.

This script orchestrates the entire workflow, from capturing user input to
executing commands. It initializes the necessary services (ASR, VLM, TTS),
manages the application's configuration, and runs the main processing loop.
"""

import os
import json
from PIL import Image
from typing import Dict, Any

# Import factory functions and interfaces from the source directory
from src.asr import get_asr_model, ASRInterface
from src.vlm import get_vlm_service, VLMInterface
from src.tts import speak
from src.audio_recorder import AudioRecorder

class AppConfig:
    """
    Centralized configuration for the application.

    This class holds all the configurable parameters, making it easy to
    manage and modify the application's behavior without changing the core logic.
    """
    # --- Service Selection ---
    # Switch between 'whisper' (real) and 'funasr' (mock)
    ASR_SERVICE: str = "whisper"
    # Switch between 'gemini' (real) and 'qwen_vl' (mock)
    VLM_SERVICE: str = "gemini"

    # --- Model & Path Configuration ---
    # Specific model name for Whisper ASR
    WHISPER_MODEL: str = "base"
    # Recording mode: 'file' for test files, 'microphone' for live recording
    RECORDING_MODE: str = "microphone"  # Change to "file" to use test files
    # Path to the test audio file (used when RECORDING_MODE is 'file')
    TEST_AUDIO_FILE: str = "test_data/test_audio.wav"
    # Path to the test image file (replace with a real camera capture function)
    TEST_IMAGE_FILE: str = "test_data/test_image_01.jpeg"

    # --- VLM Prompt Template ---
    # This is the master prompt that defines the VLM's persona, tasks, and
    # output format. Its quality is critical to the system's performance.
    VLM_PROMPT_TEMPLATE: str = """
# è§’è‰²
æ‚¨æ˜¯ä¸€ä½é«˜ç²¾åº¦ã€å®‰å…¨å„ªå…ˆçš„æ™ºæ…§ç”Ÿç”¢ç·šæ©Ÿæ¢°æ‰‹è‡‚åŠ©ç†ã€‚æ‚¨é€éæ”å½±æ©Ÿè§€å¯Ÿç”Ÿç”¢ç·šã€‚è«‹æ ¹æ“šä¸‹æ–¹å³æ™‚å½±åƒå’Œæ“ä½œå“¡çš„æŒ‡ä»¤åšå‡ºæ±ºç­–ã€‚

# æ“ä½œå“¡æŒ‡ä»¤
"{user_instruction_text}"

# æ‚¨çš„ä»»å‹™
1.  **è¦–è¦ºåˆ†æ**ï¼šä»”ç´°è§€å¯Ÿå½±åƒä¸­çš„æ‰€æœ‰ç‰©ä»¶ï¼Œç‰¹åˆ¥æ˜¯ä¸åŒé•·åº¦å’Œå­”è·çš„é‹å‹æã€èºçµ²ã€å·¥å…·å’Œææ–™æ¶ã€‚
2.  **å®šä½**ï¼šå°‡æ“ä½œå“¡æŒ‡ä»¤ä¸­çš„è©èªï¼ˆä¾‹å¦‚ã€Œé‚£å€‹é•·çš„ã€ã€ã€Œå·¦é‚Šé‚£å€‹ã€ã€ã€Œé‚£ä¸€å€‹ã€ï¼‰èˆ‡å½±åƒä¸­çš„ç‰¹å®šç‰©ä»¶é€£çµã€‚
3.  **ç³»çµ±æ§åˆ¶**ï¼šæª¢æŸ¥æ˜¯å¦ç‚ºç³»çµ±é—œé–‰æŒ‡ä»¤ï¼ˆä¾‹å¦‚ã€Œé—œé–‰ç³»çµ±ã€ã€ã€ŒçµæŸç¨‹å¼ã€ã€ã€Œåœæ­¢é‹è¡Œã€ã€ã€Œé—œæ©Ÿã€ç­‰ï¼‰ã€‚
4.  **æ­§ç¾©åµæ¸¬**ï¼š
    -   **æŒ‡å‘æ­§ç¾©**ï¼šæŒ‡ä»¤ä¸­çš„æè¿°èƒ½å¦å”¯ä¸€å°æ‡‰å½±åƒä¸­çš„ä¸€å€‹ç‰©ä»¶ï¼Ÿå¦‚æœå°æ‡‰å¤šå€‹ï¼Œå‰‡ç‚ºæ­§ç¾©ã€‚
    -   **æ„åœ–/åƒæ•¸æ­§ç¾©**ï¼šæŒ‡ä»¤æ˜¯å¦æ¸…æ¥šä¸”å¯ç›´æ¥åŸ·è¡Œï¼Ÿé‚„æ˜¯éœ€è¦æ›´å¤šè³‡è¨Šï¼Ÿä¾‹å¦‚ã€Œæˆ‘æƒ³è¦çµ„è£ä¸€å€‹å±•ç¤ºæ¶ã€æ˜¯é«˜å±¤ç´šæ„åœ–ï¼Œéœ€è¦åˆ†è§£ã€‚
5.  **æ±ºç­–èˆ‡è¼¸å‡º**ï¼š
    -   **å¦‚æœæ˜¯ç³»çµ±é—œé–‰æŒ‡ä»¤**ï¼šç”Ÿæˆé—œé–‰ç¢ºèªæ ¼å¼ã€‚
    -   **å¦‚æœæŒ‡ä»¤æ¸…æ¥šä¸”ç„¡æ­§ç¾©**ï¼šç”Ÿæˆçµæ§‹åŒ–çš„ JSON æ ¼å¼æŒ‡ä»¤ã€‚åœ¨æŒ‡ä»¤ä¸­ï¼Œä½¿ç”¨ç‰©ä»¶çš„è¦–è¦ºç‰¹å¾µæˆ–ç›¸å°ä½ç½®ä½œç‚ºæè¿°ï¼Œä¾‹å¦‚ `target_description`ã€‚
    -   **å¦‚æœæŒ‡ä»¤æœ‰æ­§ç¾©**ï¼šç”Ÿæˆæ¾„æ¸…å•é¡Œçš„ JSON æ ¼å¼ã€‚

# è¼¸å‡ºæ ¼å¼ï¼ˆå¿…é ˆåš´æ ¼éµå¾ªä»¥ä¸‹ JSON æ ¼å¼ä¹‹ä¸€ï¼‰
## ç³»çµ±é—œé–‰æ ¼å¼ï¼š
{{"action": "shutdown", "confirmation_needed": true, "message": "æ‚¨ç¢ºå®šè¦é—œé–‰ç³»çµ±å—ï¼Ÿ"}}
## æ¸…æ¥šæŒ‡ä»¤æ ¼å¼ï¼š
{{"action": "pick_up", "target_description": "ä½æ–¼ A æ¶é ‚éƒ¨ç´„ 60 å…¬åˆ†é•·çš„é‹å‹æ"}}
## æ¾„æ¸…å•é¡Œæ ¼å¼ï¼š
{{"action": "clarify", "question": "æ‚¨æ˜¯æŒ‡æˆ‘é¢å‰é‚£å€‹é•·çš„é›¶ä»¶ï¼Œç¶ è‰²ç›’å­æ—é‚Šçš„é‚£å€‹å—ï¼Ÿ"}}

# è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰
# é–‹å§‹åˆ†æï¼š
"""

def initialize_services(config: AppConfig) -> tuple[ASRInterface, VLMInterface]:
    """
    Initializes and returns the required services based on the configuration.

    Args:
        config (AppConfig): The application configuration object.

    Returns:
        A tuple containing the initialized ASR and VLM service instances.

    Raises:
        SystemExit: If any service fails to initialize.
    """
    print("--- Initializing Services ---")
    try:
        asr_service = get_asr_model(config.ASR_SERVICE, model_name=config.WHISPER_MODEL)
        # Use the latest Gemini 2.5 Flash model for better performance
        vlm_service = get_vlm_service(config.VLM_SERVICE, model_name="gemini-2.5-flash")
        print("--- Services Initialized Successfully ---\n")
        return asr_service, vlm_service
    except Exception as e:
        print(f"\n--- FATAL ERROR: Service Initialization Failed ---")
        print(f"Error: {e}")
        print("Please check your configuration, dependencies, and API keys.")
        raise SystemExit(1)

def handle_shutdown_confirmation() -> bool:
    """
    Handles the shutdown confirmation process by recording user's response.
    
    Returns:
        bool: False to shutdown, True to continue running
    """
    try:
        print("\nğŸ”´ ç³»çµ±é—œé–‰ç¢ºèªæ¨¡å¼")
        print("è«‹èªªã€Œæ˜¯ã€æˆ–ã€Œç¢ºå®šã€ä¾†é—œé–‰ç³»çµ±ï¼Œæˆ–èªªã€Œå¦ã€ã€ã€Œå–æ¶ˆã€ä¾†ç¹¼çºŒé‹è¡Œ")
        
        # Record user's confirmation
        recorder = AudioRecorder()
        confirmation_audio = recorder.record_audio(duration=3.0, countdown=True)
        
        # Use a simple ASR to get the confirmation
        from src.asr import get_asr_model
        asr_service = get_asr_model("whisper", model_name="base")
        
        confirmation_text = asr_service.transcribe(confirmation_audio).strip().lower()
        print(f"ç¢ºèªå›æ‡‰: '{confirmation_text}'")
        
        # Check for positive confirmation
        positive_words = ["æ˜¯", "å°", "ç¢ºå®š", "é—œé–‰", "å¥½", "yes", "ç¢ºèª"]
        negative_words = ["å¦", "ä¸", "å–æ¶ˆ", "ç¹¼çºŒ", "no", "ä¸è¦"]
        
        if any(word in confirmation_text for word in positive_words):
            speak("å¥½çš„ï¼Œæ­£åœ¨é—œé–‰ç³»çµ±ã€‚å†è¦‹ï¼")
            print("ğŸ‘‹ ç”¨æˆ¶ç¢ºèªé—œé–‰ç³»çµ±")
            return False  # Shutdown
        elif any(word in confirmation_text for word in negative_words):
            speak("å¥½çš„ï¼Œç¹¼çºŒé‹è¡Œç³»çµ±ã€‚")
            print("âœ… ç”¨æˆ¶å–æ¶ˆé—œé–‰ï¼Œç¹¼çºŒé‹è¡Œ")
            return True  # Continue
        else:
            speak("æˆ‘æ²’æœ‰è½æ¸…æ¥šæ‚¨çš„å›æ‡‰ï¼Œç³»çµ±å°‡ç¹¼çºŒé‹è¡Œã€‚")
            print("â“ ç„¡æ³•è­˜åˆ¥ç¢ºèªå›æ‡‰ï¼Œé è¨­ç¹¼çºŒé‹è¡Œ")
            return True  # Continue by default
            
    except Exception as e:
        print(f"é—œé–‰ç¢ºèªéç¨‹å‡ºéŒ¯: {e}")
        speak("ç¢ºèªéç¨‹å‡ºç¾å•é¡Œï¼Œç³»çµ±å°‡ç¹¼çºŒé‹è¡Œã€‚")
        return True  # Continue on error
    finally:
        # Clean up confirmation audio file
        try:
            if 'confirmation_audio' in locals():
                recorder.cleanup_temp_file(confirmation_audio)
        except:
            pass

def get_user_inputs(config: AppConfig) -> tuple[str, Image.Image]:
    """
    Gets user inputs either from files or by recording from microphone.

    Args:
        config (AppConfig): Application configuration containing recording mode and file paths.

    Returns:
        A tuple containing the audio file path and the loaded PIL Image object.
    """
    # Always load the image from file
    image_path = config.TEST_IMAGE_FILE
    if not os.path.exists(image_path):
        print(f"ERROR: Image file not found at {image_path}")
        raise FileNotFoundError
    
    image = Image.open(image_path)
    print(f"Loaded image: {os.path.basename(image_path)} (Size: {image.size})")
    
    # Handle audio input based on recording mode
    if config.RECORDING_MODE == "microphone":
        print("--- ä½¿ç”¨éº¥å…‹é¢¨éŒ„éŸ³æ¨¡å¼ ---")
        recorder = AudioRecorder()
        
        # Optional: List available audio devices for debugging
        # recorder.list_audio_devices()
        
        try:
            # Record audio from microphone
            audio_path = recorder.record_audio(duration=5.0)
            print(f"éŒ„éŸ³å®Œæˆï¼Œå„²å­˜è‡³: {os.path.basename(audio_path)}")
            return audio_path, image
        except Exception as e:
            print(f"éº¥å…‹é¢¨éŒ„éŸ³å¤±æ•—: {e}")
            print("åˆ‡æ›è‡³æª”æ¡ˆæ¨¡å¼...")
            # Fall back to file mode if microphone fails
            audio_path = config.TEST_AUDIO_FILE
    else:
        print("--- ä½¿ç”¨éŸ³æª”æ¨¡å¼ ---")
        audio_path = config.TEST_AUDIO_FILE
    
    # File mode validation
    if not os.path.exists(audio_path):
        print(f"ERROR: Audio file not found at {audio_path}")
        raise FileNotFoundError
    
    print(f"Loaded audio: {os.path.basename(audio_path)}")
    return audio_path, image

def process_command(asr: ASRInterface, vlm: VLMInterface, audio_path: str, image: Image.Image, prompt_template: str) -> bool:
    """
    Executes the core logic: transcribe, decide, and act.

    Args:
        asr (ASRInterface): The initialized ASR service.
        vlm (VLMInterface): The initialized VLM service.
        audio_path (str): Path to the user's audio command.
        image (Image.Image): The visual context for the command.
        prompt_template (str): The master prompt for the VLM.
        
    Returns:
        bool: True to continue running, False to shutdown the system.
    """
    # 1. Transcribe Audio to Text
    print("\n--- Step 1: Transcribing Audio ---")
    try:
        instruction_text = asr.transcribe(audio_path)
        print(f"ASR Output: '{instruction_text}'")
        if not instruction_text.strip():
            speak("æˆ‘æ²’æœ‰è½æ¸…æ¥šï¼Œè«‹æ‚¨å†èªªä¸€æ¬¡å¥½å—ï¼Ÿ")
            return True  # Continue running
    except FileNotFoundError as e:
        print(f"ASR Error: {e}. This often means 'ffmpeg' is not installed or not in the system's PATH.")
        speak("æˆ‘çš„éŸ³é »è™•ç†å·¥å…·å‡ºç¾å•é¡Œï¼Œè«‹æª¢æŸ¥ç³»çµ±è¨­å®šã€‚")
        return True  # Continue running
    except Exception as e:
        print(f"ASR Error: An unexpected error occurred: {e}")
        speak("æˆ‘åœ¨ç†è§£æ‚¨çš„è©±æ™‚é‡åˆ°äº†éŒ¯èª¤ã€‚")
        return True  # Continue running

    # 2. Get Decision from VLM
    print("\n--- Step 2: Getting Decision from VLM ---")
    final_prompt = prompt_template.format(user_instruction_text=instruction_text)
    try:
        vlm_response_str = vlm.get_decision(final_prompt, image)
        print(f"VLM Raw Response: {vlm_response_str}")
    except Exception as e:
        print(f"VLM Error: {e}")
        speak("æˆ‘ç„¡æ³•é€£æ¥åˆ°è¦–è¦ºæ¨ç†ä¸­å¿ƒï¼Œè«‹æª¢æŸ¥é€£ç·šæˆ– API é‡‘é‘°ã€‚")
        return True  # Continue running

    # 3. Process VLM Response and Provide Feedback
    print("\n--- Step 3: Processing Response and Acting ---")
    try:
        # Clean up the response by removing markdown code blocks if present
        cleaned_response = vlm_response_str.strip()
        
        # Remove markdown code blocks
        if cleaned_response.startswith("```json"):
            cleaned_response = cleaned_response[7:]
        if cleaned_response.endswith("```"):
            cleaned_response = cleaned_response[:-3]
        
        # Extract JSON from response that might have explanatory text
        import re
        json_match = re.search(r'\{.*\}', cleaned_response, re.DOTALL)
        if json_match:
            cleaned_response = json_match.group(0)
        
        cleaned_response = cleaned_response.strip()
        
        decision = json.loads(cleaned_response)
        action = decision.get("action")

        if action == "shutdown":
            # Handle system shutdown request
            confirmation_message = decision.get("message", "æ‚¨ç¢ºå®šè¦é—œé–‰ç³»çµ±å—ï¼Ÿ")
            print(f"Action: Shutdown Request -> Asking: '{confirmation_message}'")
            speak(confirmation_message)
            
            # Get confirmation from user
            return handle_shutdown_confirmation()
            
        elif action == "clarify":
            question = decision.get("question", "æˆ‘æœ‰å€‹å•é¡Œï¼Œä½†ä¸ç¢ºå®šæ˜¯ä»€éº¼ã€‚")
            print(f"Action: Clarify -> Asking: '{question}'")
            speak(question)
            return True  # Continue running
            
        elif action == "pick_up":
            target = decision.get("target_description", "æŒ‡å®šçš„ç‰©ä»¶")
            confirmation_text = f"å¥½çš„ï¼Œæˆ‘ç¾åœ¨æœƒæ‹¿èµ·{target}ã€‚"
            print(f"Action: Execute -> Task: '{confirmation_text}'")
            speak(confirmation_text)
            # In a real system, this is where you would call the robot control module.
            return True  # Continue running
            
        else:
            print(f"Warning: Received unknown action '{action}' from VLM.")
            speak("æˆ‘æ”¶åˆ°äº†ä¸€å€‹è¨ˆåŠƒï¼Œä½†ä¸ç¢ºå®šå¦‚ä½•åŸ·è¡Œã€‚")
            return True  # Continue running
    except json.JSONDecodeError:
        print("VLM Error: Response was not valid JSON. Speaking raw response.")
        speak("æˆ‘çš„æ€è€ƒéç¨‹å‡ºç¾æ ¼å¼éŒ¯èª¤ï¼Œä»¥ä¸‹æ˜¯æˆ‘çš„æƒ³æ³•ï¼š")
        speak(vlm_response_str)
        return True  # Continue running
    except Exception as e:
        print(f"Error during action processing: {e}")
        speak("æˆ‘åœ¨åŸ·è¡ŒæŒ‡ä»¤æ™‚é‡åˆ°äº†éŒ¯èª¤ã€‚")
        return True  # Continue running

def main():
    """
    Main function to run the VLM-enhanced robot assistant workflow.
    The system runs continuously until the user requests shutdown.
    """
    print("=============================================")
    print("  VLM-Enhanced Robot Assistant Initializing  ")
    print("=============================================")
    
    config = AppConfig()
    asr_service, vlm_service = initialize_services(config)
    
    print("ğŸ¤– ç³»çµ±å·²å•Ÿå‹•ï¼èªªã€Œé—œé–‰ç³»çµ±ã€ä¾†å®‰å…¨é€€å‡º")
    print("=============================================\n")
    
    # Main processing loop
    session_count = 0
    while True:
        session_count += 1
        audio_path = None
        
        try:
            print(f"\nğŸ”„ === ç¬¬ {session_count} æ¬¡äº’å‹• ===")
            audio_file, image_file = get_user_inputs(config)
            audio_path = audio_file
            
            # Process command and check if system should continue
            should_continue = process_command(asr_service, vlm_service, audio_file, image_file, config.VLM_PROMPT_TEMPLATE)
            
            if not should_continue:
                print("\nğŸ›‘ ç³»çµ±æ­£åœ¨é—œé–‰...")
                break
                
            print(f"âœ… ç¬¬ {session_count} æ¬¡äº’å‹•å®Œæˆ\n")
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸ æª¢æ¸¬åˆ° Ctrl+Cï¼Œæ­£åœ¨å®‰å…¨é—œé–‰ç³»çµ±...")
            speak("æª¢æ¸¬åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰ç³»çµ±ã€‚")
            break
            
        except FileNotFoundError:
            print("\n--- è­¦å‘Š: æ‰¾ä¸åˆ°å¿…è¦çš„è¼¸å…¥æª”æ¡ˆ ---")
            speak("æˆ‘æ‰¾ä¸åˆ°å¿…è¦çš„è¼¸å…¥æª”æ¡ˆï¼Œè«‹æª¢æŸ¥è¨­å®šã€‚")
            print("ç³»çµ±å°‡ç¹¼çºŒç­‰å¾…ä¸‹ä¸€å€‹æŒ‡ä»¤...\n")
            
        except Exception as e:
            print(f"\n--- ç™¼ç”Ÿæœªè™•ç†çš„ç•°å¸¸ ---")
            print(f"éŒ¯èª¤: {e}")
            speak("ç™¼ç”Ÿäº†éŒ¯èª¤ï¼Œä½†ç³»çµ±å°‡ç¹¼çºŒé‹è¡Œã€‚")
            print("ç³»çµ±å°‡ç¹¼çºŒç­‰å¾…ä¸‹ä¸€å€‹æŒ‡ä»¤...\n")
            
        finally:
            # Clean up temporary recording file if it was created
            if audio_path and config.RECORDING_MODE == "microphone":
                try:
                    recorder = AudioRecorder()
                    recorder.cleanup_temp_file(audio_path)
                except:
                    pass  # Ignore cleanup errors

    print("\n=============================================")
    print("           ç³»çµ±å·²å®‰å…¨é—œé–‰           ")
    print(f"           ç¸½å…±è™•ç†äº† {session_count} æ¬¡äº’å‹•           ")
    print("=============================================")

if __name__ == "__main__":
    main()
